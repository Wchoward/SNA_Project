{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from math import cos, sin, atan2, sqrt, pi, radians, degrees, asin\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    x = x[:4] + ' ' + x[4:6] + ' '+x[6:]\n",
    "    return datetime.strptime(x, '%Y %m %d')\n",
    "def read_data(file):\n",
    "    return pd.read_csv(file, parse_dates=['date'], date_parser=parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = read_data('data1/A.csv')\n",
    "B = read_data('data1/B.csv')\n",
    "C = read_data('data1/C.csv')\n",
    "D = read_data('data1/D.csv')\n",
    "E = read_data('data1/E.csv')\n",
    "n_features = A.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "n_step = 1\n",
    "# n_features = 52\n",
    "n_ob = n_step * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def process(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        # reframed.drop(reframed.columns[range(53, 104)], axis=1, inplace=True)\n",
    "        v.append(reframed.values)\n",
    "        a = v[0]\n",
    "        for i in range(1, len(v)):\n",
    "            a = np.concatenate((a, v[i]), axis=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A1 = read_data('data/A1.csv')\n",
    "a = process(A)\n",
    "b = process(B)\n",
    "c = process(C)\n",
    "d = process(D)\n",
    "e = process(E)\n",
    "data = np.concatenate((a,b,c,d,e),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:, :n_ob], data[:, n_ob:], test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nTrain on 13798 samples, validate on 3450 samples\nEpoch 1/10\n - 9s - loss: 0.5881 - val_loss: 0.3554\nEpoch 2/10\n - 8s - loss: 0.3184 - val_loss: 0.2677\nEpoch 3/10\n - 7s - loss: 0.2563 - val_loss: 0.2245\nEpoch 4/10\n - 7s - loss: 0.2206 - val_loss: 0.1969\nEpoch 5/10\n - 7s - loss: 0.1967 - val_loss: 0.1768\nEpoch 6/10\n - 7s - loss: 0.1786 - val_loss: 0.1631\nEpoch 7/10\n - 8s - loss: 0.1636 - val_loss: 0.1517\nEpoch 8/10\n - 8s - loss: 0.1530 - val_loss: 0.1422\nEpoch 9/10\n - 7s - loss: 0.1453 - val_loss: 0.1357\nEpoch 10/10\n - 7s - loss: 0.1380 - val_loss: 0.1298\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a3573ff60>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], n_features, n_step))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], n_features, n_step))\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_test.shape[1], X_test.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_features))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='msle', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "yhat = model.predict(X_test)\n",
    "# print(yhat)\n",
    "# x_test0 = X_test.reshape((X_test.shape[0], n_features*n_step))\n",
    "# inv_yhat = np.concatenate((yhat, x_test0[:, n_ob:]), axis=1)\n",
    "# inv_yhat = scaler.inverse_transform(yhat)\n",
    "# inv_yhat = inv_yhat[:, 0]\n",
    "# y_test = y_test.reshape((len(y_test), n_features))\n",
    "# inv_y = np.concatenate((y_test, x_test0[:, n_ob:]), axis=1)\n",
    "# inv_y = scaler.inverse_transform(y_test)\n",
    "# inv_y = inv_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test RMSE: 361.522\n"
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_last_day(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        v.append(np.array([reframed.values[-1]])[:,n_ob:])\n",
    "    return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lastday = process_last_day(A)\n",
    "b_lastday = process_last_day(B)\n",
    "c_lastday = process_last_day(C)\n",
    "d_lastday = process_last_day(D)\n",
    "e_lastday = process_last_day(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(day_before):\n",
    "    day_before = np.reshape(day_before, (day_before.shape[0], n_features, n_step))\n",
    "    # day_before = np.reshape(day_before, (day_before.shape[0], n_step, n_features))\n",
    "    day_after = model.predict(day_before)\n",
    "    return day_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_future_prediction(lastday):\n",
    "    res_city_lst = []\n",
    "    for region_begin in lastday:\n",
    "        res_date_lst = [predict(region_begin)]\n",
    "        for i in range(1, 30):\n",
    "            res_date_lst.append(predict(res_date_lst[-1]))\n",
    "        res_city_lst.append(res_date_lst)\n",
    "    return res_city_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prediction = generate_future_prediction(a_lastday)\n",
    "b_prediction = generate_future_prediction(b_lastday)\n",
    "c_prediction = generate_future_prediction(c_lastday)\n",
    "d_prediction = generate_future_prediction(d_lastday)\n",
    "e_prediction = generate_future_prediction(e_lastday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[37.663475  ,  0.29587582,  0.33411047,  7.479507  ]],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "a_prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res_infection_lst(cities_prediction):\n",
    "    res_infection = []\n",
    "    res_region = []\n",
    "    for city_prediction in cities_prediction:\n",
    "        region_id = 0\n",
    "        for region in city_prediction:\n",
    "            for date in region:\n",
    "                res_infection.append(int(round(date[0][0])))\n",
    "                res_region.append(region_id)\n",
    "            region_id = region_id + 1\n",
    "    return res_infection, res_region\n",
    "def check_minus(infection):\n",
    "    for i in range(len(infection)):\n",
    "        if infection[i] < 0:\n",
    "            if infection[i - 1] < 6:\n",
    "                infection[i] = 0\n",
    "            else:\n",
    "                infection[i] = int(infection[i - 1])\n",
    "    return infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "infection, region = generate_res_infection_lst([a_prediction,b_prediction,c_prediction,d_prediction,e_prediction])\n",
    "infection = check_minus(infection)\n",
    "submission = pd.read_csv('data/submission.csv', header=None, names=['city','region','date','infection'])\n",
    "submission['infection'] = infection\n",
    "submission['region'] = region\n",
    "submission.to_csv('data/test_submission_double_LSTM.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python36964bittensorflowconda0768426cf85c4c639c5d84af9151c906"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}