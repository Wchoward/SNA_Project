{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from math import cos, sin, atan2, sqrt, pi, radians, degrees, asin\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    x = x[:4] + ' ' + x[4:6] + ' '+x[6:]\n",
    "    return datetime.strptime(x, '%Y %m %d')\n",
    "def read_data(file):\n",
    "    return pd.read_csv(file, parse_dates=['date'], date_parser=parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = read_data('data1/A.csv')\n",
    "B = read_data('data1/B.csv')\n",
    "C = read_data('data1/C.csv')\n",
    "D = read_data('data1/D.csv')\n",
    "E = read_data('data1/E.csv')\n",
    "n_features = A.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "n_step = 1\n",
    "n_ob = n_step * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def process(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        # reframed.drop(reframed.columns[range(53, 104)], axis=1, inplace=True)\n",
    "        v.append(reframed.values)\n",
    "        a = v[0]\n",
    "        for i in range(1, len(v)):\n",
    "            a = np.concatenate((a, v[i]), axis=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A1 = read_data('data/A1.csv')\n",
    "a = process(A)\n",
    "b = process(B)\n",
    "c = process(C)\n",
    "d = process(D)\n",
    "e = process(E)\n",
    "data = np.concatenate((a,b,c,d,e),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:, :n_ob], data[:, n_ob:], test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], n_step, n_features))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], n_step, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 13798 samples, validate on 3450 samples\nEpoch 1/20\n - 3s - loss: 8.7472 - val_loss: 8.7038\nEpoch 2/20\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-316d9bc7879e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m\"\"\"The graph that was launched in this session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(X_test.shape[1], X_test.shape[2])))\n",
    "# model.add(LSTM(units=52))\n",
    "model.add(Dense(n_features))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='msle', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=16, validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "yhat = model.predict(X_test)\n",
    "# print(yhat)\n",
    "# x_test0 = X_test.reshape((X_test.shape[0], n_features*n_step))\n",
    "# inv_yhat = np.concatenate((yhat, x_test0[:, n_ob:]), axis=1)\n",
    "# inv_yhat = scaler.inverse_transform(yhat)\n",
    "# inv_yhat = inv_yhat[:, 0]\n",
    "# y_test = y_test.reshape((len(y_test), n_features))\n",
    "# inv_y = np.concatenate((y_test, x_test0[:, n_ob:]), axis=1)\n",
    "# inv_y = scaler.inverse_transform(y_test)\n",
    "# inv_y = inv_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test RMSE: 691.122\n"
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_last_day(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        v.append(np.array([reframed.values[-1]])[:,n_ob:])\n",
    "    return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lastday = process_last_day(A)\n",
    "b_lastday = process_last_day(B)\n",
    "c_lastday = process_last_day(C)\n",
    "d_lastday = process_last_day(D)\n",
    "e_lastday = process_last_day(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(day_before):\n",
    "    day_before = np.reshape(day_before, (day_before.shape[0], n_step, n_features))\n",
    "    day_after = model.predict(day_before)\n",
    "    return day_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_future_prediction(lastday):\n",
    "    res_city_lst = []\n",
    "    for region_begin in lastday:\n",
    "        print(region_begin)\n",
    "        res_date_lst = [predict(region_begin)]\n",
    "        for i in range(1, 30):\n",
    "            res_date_lst.append(predict(res_date_lst[-1]))\n",
    "        res_city_lst.append(res_date_lst)\n",
    "    return res_city_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[32.]]\n[[96.]]\n[[77.]]\n[[14.]]\n[[10.]]\n[[24.]]\n[[21.]]\n[[36.]]\n[[36.]]\n[[89.]]\n[[120.]]\n[[73.]]\n[[211.]]\n[[98.]]\n[[146.]]\n[[80.]]\n[[40.]]\n[[46.]]\n[[82.]]\n[[213.]]\n[[248.]]\n[[129.]]\n[[27.]]\n[[58.]]\n[[53.]]\n[[47.]]\n[[34.]]\n[[81.]]\n[[54.]]\n[[88.]]\n[[261.]]\n[[249.]]\n[[153.]]\n[[146.]]\n[[29.]]\n[[66.]]\n[[102.]]\n[[135.]]\n[[209.]]\n[[187.]]\n[[78.]]\n[[146.]]\n[[132.]]\n[[162.]]\n[[53.]]\n[[84.]]\n[[32.]]\n[[15.]]\n[[78.]]\n[[61.]]\n[[87.]]\n[[251.]]\n[[234.]]\n[[154.]]\n[[98.]]\n[[108.]]\n[[125.]]\n[[262.]]\n[[19.]]\n[[42.]]\n[[108.]]\n[[20.]]\n[[119.]]\n[[3.]]\n[[190.]]\n[[176.]]\n[[127.]]\n[[113.]]\n[[129.]]\n[[20.]]\n[[58.]]\n[[67.]]\n[[43.]]\n[[62.]]\n[[97.]]\n[[84.]]\n[[84.]]\n[[9.]]\n[[53.]]\n[[57.]]\n[[75.]]\n[[61.]]\n[[10.]]\n[[146.]]\n[[85.]]\n[[18.]]\n[[4.]]\n[[56.]]\n[[80.]]\n[[221.]]\n[[139.]]\n[[50.]]\n[[30.]]\n[[31.]]\n[[13.]]\n[[55.]]\n[[181.]]\n[[72.]]\n[[143.]]\n[[46.]]\n[[29.]]\n[[48.]]\n[[13.]]\n[[24.]]\n[[93.]]\n[[15.]]\n[[16.]]\n[[116.]]\n[[162.]]\n[[19.]]\n[[10.]]\n[[82.]]\n[[7.]]\n[[44.]]\n[[99.]]\n[[20.]]\n[[138.]]\n[[280.]]\n[[50.]]\n[[284.]]\n[[16.]]\n[[298.]]\n[[443.]]\n[[250.]]\n[[301.]]\n[[163.]]\n[[116.]]\n[[74.]]\n[[56.]]\n[[32.]]\n[[31.]]\n[[26.]]\n[[117.]]\n[[223.]]\n[[742.]]\n[[241.]]\n[[3.]]\n[[81.]]\n[[3094.]]\n[[168.]]\n[[47.]]\n[[47.]]\n[[270.]]\n[[32.]]\n[[267.]]\n[[94.]]\n[[23.]]\n[[33.]]\n[[235.]]\n[[274.]]\n[[180.]]\n[[71.]]\n[[108.]]\n[[109.]]\n[[61.]]\n[[159.]]\n[[71.]]\n[[132.]]\n[[325.]]\n[[1237.]]\n[[523.]]\n[[121.]]\n[[47.]]\n[[164.]]\n[[290.]]\n[[127.]]\n[[1694.]]\n[[59.]]\n[[43.]]\n[[94.]]\n[[64.]]\n[[333.]]\n[[106.]]\n[[92.]]\n[[170.]]\n[[2487.]]\n[[2237.]]\n[[359.]]\n[[216.]]\n[[278.]]\n[[3658.]]\n[[6608.]]\n[[2459.]]\n[[116.]]\n[[4424.]]\n[[294.]]\n[[4118.]]\n[[992.]]\n[[399.]]\n[[247.]]\n[[193.]]\n[[689.]]\n[[345.]]\n[[301.]]\n[[293.]]\n[[56.]]\n[[298.]]\n[[1008.]]\n[[105.]]\n[[189.]]\n[[492.]]\n[[1847.]]\n[[406.]]\n[[548.]]\n[[195.]]\n[[4650.]]\n[[1574.]]\n[[54.]]\n[[523.]]\n[[260.]]\n[[155.]]\n[[5771.]]\n[[85.]]\n[[249.]]\n[[2055.]]\n[[588.]]\n[[64.]]\n[[2021.]]\n[[5258.]]\n[[38.]]\n[[185.]]\n[[466.]]\n[[176.]]\n[[125.]]\n[[297.]]\n[[1883.]]\n[[131.]]\n[[270.]]\n[[89.]]\n[[908.]]\n[[451.]]\n[[499.]]\n[[193.]]\n[[558.]]\n[[385.]]\n[[372.]]\n[[864.]]\n[[986.]]\n[[1101.]]\n[[83.]]\n[[106.]]\n[[283.]]\n[[101.]]\n[[200.]]\n[[845.]]\n[[95.]]\n[[251.]]\n[[401.]]\n[[616.]]\n[[201.]]\n[[97.]]\n[[1401.]]\n[[209.]]\n[[428.]]\n[[842.]]\n[[881.]]\n[[1303.]]\n[[1502.]]\n[[106.]]\n[[753.]]\n[[2012.]]\n[[317.]]\n[[350.]]\n[[196.]]\n[[146.]]\n[[101.]]\n[[907.]]\n[[166.]]\n[[54.]]\n[[153.]]\n[[318.]]\n[[83.]]\n[[223.]]\n[[161.]]\n[[342.]]\n[[66.]]\n[[351.]]\n[[268.]]\n[[217.]]\n[[286.]]\n[[1639.]]\n[[222.]]\n[[93.]]\n[[363.]]\n[[294.]]\n[[93.]]\n[[56.]]\n[[9.]]\n[[64.]]\n[[14.]]\n[[23.]]\n[[443.]]\n[[36.]]\n[[98.]]\n[[2666.]]\n[[792.]]\n[[375.]]\n[[724.]]\n[[268.]]\n[[60.]]\n[[18.]]\n[[51.]]\n[[157.]]\n[[535.]]\n[[12.]]\n[[11.]]\n[[224.]]\n[[9.]]\n[[38.]]\n[[21.]]\n[[108.]]\n[[157.]]\n[[292.]]\n[[6.]]\n[[12.]]\n[[2.]]\n[[13.]]\n[[11.]]\n[[48.]]\n[[1.]]\n[[75.]]\n[[241.]]\n[[2116.]]\n[[688.]]\n[[37.]]\n[[4.]]\n[[124.]]\n[[131.]]\n[[5.]]\n[[4.]]\n[[170.]]\n[[308.]]\n[[32.]]\n[[17.]]\n[[3.]]\n[[39.]]\n[[9.]]\n[[4.]]\n[[96.]]\n[[0.]]\n[[7.]]\n[[1.]]\n[[24.]]\n[[66.]]\n[[41.]]\n[[10.]]\n[[40.]]\n[[3.]]\n[[54.]]\n[[2.]]\n[[44.]]\n[[13.]]\n[[24.]]\n[[30.]]\n[[36.]]\n[[37.]]\n[[80.]]\n[[58.]]\n[[43.]]\n[[35.]]\n[[377.]]\n[[190.]]\n[[123.]]\n[[29.]]\n[[85.]]\n[[949.]]\n[[364.]]\n[[30.]]\n[[53.]]\n[[100.]]\n[[179.]]\n[[52.]]\n[[42.]]\n[[489.]]\n[[61.]]\n[[0.]]\n[[4.]]\n[[1.]]\n[[120.]]\n[[8.]]\n[[18.]]\n[[39.]]\n[[41.]]\n[[95.]]\n[[12.]]\n[[8.]]\n[[43.]]\n[[6.]]\n[[41.]]\n[[25.]]\n[[29.]]\n[[4.]]\n"
    }
   ],
   "source": [
    "a_prediction = generate_future_prediction(a_lastday)\n",
    "b_prediction = generate_future_prediction(b_lastday)\n",
    "c_prediction = generate_future_prediction(c_lastday)\n",
    "d_prediction = generate_future_prediction(d_lastday)\n",
    "e_prediction = generate_future_prediction(e_lastday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[37.35141]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "a_prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res_infection_lst(cities_prediction):\n",
    "    res_infection = []\n",
    "    res_region = []\n",
    "    for city_prediction in cities_prediction:\n",
    "        region_id = 0\n",
    "        for region in city_prediction:\n",
    "            for date in region:\n",
    "                res_infection.append(int(round(date[0][0])))\n",
    "                res_region.append(region_id)\n",
    "            region_id = region_id + 1\n",
    "    return res_infection, res_region\n",
    "def check_minus(infection):\n",
    "    for i in range(len(infection)):\n",
    "        if infection[i] < 0:\n",
    "            if infection[i - 1] < 6:\n",
    "                infection[i] = 0\n",
    "            else:\n",
    "                infection[i] = int(infection[i - 1])\n",
    "    return infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "infection, region = generate_res_infection_lst([a_prediction,b_prediction,c_prediction,d_prediction,e_prediction])\n",
    "infection = check_minus(infection)\n",
    "submission = pd.read_csv('data/submission.csv', header=None, names=['city','region','date','infection'])\n",
    "submission['infection'] = infection\n",
    "submission['region'] = region\n",
    "submission.to_csv('data/test_submission_single_LSTM.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result  \n",
    "100 - 97.669  \n",
    "80 - 98.666  \n",
    "70 - 98.581    \n",
    "50 - 99.553  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python36964bittensorflowconda0768426cf85c4c639c5d84af9151c906"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}