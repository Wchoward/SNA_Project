{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from math import cos, sin, atan2, sqrt, pi ,radians, degrees, asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_density = pd.read_csv('dataset/train_data/city_A/density.csv',header=None,names=['date', 'hour', 'grid_x', 'grid_y','index'])\n",
    "df_grid = pd.read_csv('dataset/train_data/city_A/grid_attr.csv',header=None, names=['grid_x', 'grid_y', 'region_id'])\n",
    "df_date = pd.read_csv('dataset/train_data/city_A/infection.csv',header=None,names=['city_id', 'region_id', 'date', 'index'])\n",
    "df_A = pd.read_csv('work/data/A.csv')\n",
    "result_inner = pd.merge(df_density, df_grid,how='inner',on=['grid_x','grid_y'])\n",
    "density_res = result_inner.drop(['grid_x','grid_y'], axis=1)\n",
    "density_res = density_res.groupby(['region_id','date'])['index'].mean().reset_index()\n",
    "df_date = pd.DataFrame(df_date, columns=['date', 'region_id'])\n",
    "density_res_all = pd.merge(density_res,df_date,how = 'right', on=['date','region_id'])\n",
    "density_res_all.sort_values(['region_id','date'], ascending = [True,True], inplace=True)\n",
    "density_res_all.reset_index(drop=True)\n",
    "density_res_all.fillna(method='ffill',inplace=True)\n",
    "density_res_all.fillna(method='bfill',inplace=True)\n",
    "density_res_all.columns = ['region','date','density']\n",
    "df = pd.merge(df_A, density_res_all, how='inner', on=['region','date'])\n",
    "df.to_csv('work/data/A(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_density = pd.read_csv('dataset/train_data/city_B/density.csv',header=None,names=['date', 'hour', 'grid_x', 'grid_y','index'])\n",
    "df_grid = pd.read_csv('dataset/train_data/city_B/grid_attr.csv',header=None, names=['grid_x', 'grid_y', 'region_id'])\n",
    "df_date = pd.read_csv('dataset/train_data/city_B/infection.csv',header=None,names=['city_id', 'region_id', 'date', 'index'])\n",
    "df_A = pd.read_csv('work/data/B.csv')\n",
    "result_inner = pd.merge(df_density, df_grid,how='inner',on=['grid_x','grid_y'])\n",
    "density_res = result_inner.drop(['grid_x','grid_y'], axis=1)\n",
    "density_res = density_res.groupby(['region_id','date'])['index'].mean().reset_index()\n",
    "df_date = pd.DataFrame(df_date, columns=['date', 'region_id'])\n",
    "density_res_all = pd.merge(density_res,df_date,how = 'right', on=['date','region_id'])\n",
    "density_res_all.sort_values(['region_id','date'], ascending = [True,True], inplace=True)\n",
    "density_res_all.reset_index(drop=True)\n",
    "density_res_all.fillna(method='ffill',inplace=True)\n",
    "density_res_all.fillna(method='bfill',inplace=True)\n",
    "density_res_all.columns = ['region','date','density']\n",
    "df = pd.merge(df_A, density_res_all, how='inner', on=['region','date'])\n",
    "df.to_csv('work/data/B(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_density = pd.read_csv('dataset/train_data/city_C/density.csv',header=None,names=['date', 'hour', 'grid_x', 'grid_y','index'])\n",
    "df_grid = pd.read_csv('dataset/train_data/city_C/grid_attr.csv',header=None, names=['grid_x', 'grid_y', 'region_id'])\n",
    "df_date = pd.read_csv('dataset/train_data/city_C/infection.csv',header=None,names=['city_id', 'region_id', 'date', 'index'])\n",
    "df_A = pd.read_csv('work/data/C.csv')\n",
    "result_inner = pd.merge(df_density, df_grid,how='inner',on=['grid_x','grid_y'])\n",
    "density_res = result_inner.drop(['grid_x','grid_y'], axis=1)\n",
    "density_res = density_res.groupby(['region_id','date'])['index'].mean().reset_index()\n",
    "df_date = pd.DataFrame(df_date, columns=['date', 'region_id'])\n",
    "density_res_all = pd.merge(density_res,df_date,how = 'right', on=['date','region_id'])\n",
    "density_res_all.sort_values(['region_id','date'], ascending = [True,True], inplace=True)\n",
    "density_res_all.reset_index(drop=True)\n",
    "density_res_all.fillna(method='ffill',inplace=True)\n",
    "density_res_all.fillna(method='bfill',inplace=True)\n",
    "density_res_all.columns = ['region','date','density']\n",
    "df = pd.merge(df_A, density_res_all, how='inner', on=['region','date'])\n",
    "df.to_csv('work/data/C(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_density = pd.read_csv('dataset/train_data/city_D/density.csv',header=None,names=['date', 'hour', 'grid_x', 'grid_y','index'])\n",
    "df_grid = pd.read_csv('dataset/train_data/city_D/grid_attr.csv',header=None, names=['grid_x', 'grid_y', 'region_id'])\n",
    "df_date = pd.read_csv('dataset/train_data/city_D/infection.csv',header=None,names=['city_id', 'region_id', 'date', 'index'])\n",
    "df_A = pd.read_csv('work/data/D.csv')\n",
    "result_inner = pd.merge(df_density, df_grid,how='inner',on=['grid_x','grid_y'])\n",
    "density_res = result_inner.drop(['grid_x','grid_y'], axis=1)\n",
    "density_res = density_res.groupby(['region_id','date'])['index'].mean().reset_index()\n",
    "df_date = pd.DataFrame(df_date, columns=['date', 'region_id'])\n",
    "density_res_all = pd.merge(density_res,df_date,how = 'right', on=['date','region_id'])\n",
    "density_res_all.sort_values(['region_id','date'], ascending = [True,True], inplace=True)\n",
    "density_res_all.reset_index(drop=True)\n",
    "density_res_all.fillna(method='ffill',inplace=True)\n",
    "density_res_all.fillna(method='bfill',inplace=True)\n",
    "density_res_all.columns = ['region','date','density']\n",
    "df = pd.merge(df_A, density_res_all, how='inner', on=['region','date'])\n",
    "df.to_csv('work/data/D(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_density = pd.read_csv('dataset/train_data/city_E/density.csv',header=None,names=['date', 'hour', 'grid_x', 'grid_y','index'])\n",
    "df_grid = pd.read_csv('dataset/train_data/city_E/grid_attr.csv',header=None, names=['grid_x', 'grid_y', 'region_id'])\n",
    "df_date = pd.read_csv('dataset/train_data/city_E/infection.csv',header=None,names=['city_id', 'region_id', 'date', 'index'])\n",
    "df_A = pd.read_csv('work/data/E.csv')\n",
    "result_inner = pd.merge(df_density, df_grid,how='inner',on=['grid_x','grid_y'])\n",
    "density_res = result_inner.drop(['grid_x','grid_y'], axis=1)\n",
    "density_res = density_res.groupby(['region_id','date'])['index'].mean().reset_index()\n",
    "df_date = pd.DataFrame(df_date, columns=['date', 'region_id'])\n",
    "density_res_all = pd.merge(density_res,df_date,how = 'right', on=['date','region_id'])\n",
    "density_res_all.sort_values(['region_id','date'], ascending = [True,True], inplace=True)\n",
    "density_res_all.reset_index(drop=True)\n",
    "density_res_all.fillna(method='ffill',inplace=True)\n",
    "density_res_all.fillna(method='bfill',inplace=True)\n",
    "density_res_all.columns = ['region','date','density']\n",
    "df = pd.merge(df_A, density_res_all, how='inner', on=['region','date'])\n",
    "df.to_csv('work/data/E(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_dict = {}\n",
    "with open('dataset/train_data/city_A/grid_attr.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        items = line.strip().split(',')\n",
    "        axis = \",\".join(items[0:2])\n",
    "        ID = items[2]\n",
    "        # grid_dict[axis] = \"_\".join(['city_A', ID])\n",
    "        grid_dict[axis] = ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_geolocation(geolocations):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    z = 0\n",
    "    lenth = len(geolocations)\n",
    "    for lon, lat in geolocations:\n",
    "        lon = radians(float(lon))\n",
    "        lat = radians(float(lat))\n",
    "        x += cos(lat) * cos(lon)\n",
    "        y += cos(lat) * sin(lon)\n",
    "        z += sin(lat)\n",
    "    x = float(x / lenth)\n",
    "    y = float(y / lenth)\n",
    "    z = float(z / lenth)\n",
    "    return (degrees(atan2(y, x)), degrees(atan2(z, sqrt(x * x + y * y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def haversine(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    计算两经纬度之间的距离\n",
    "    \"\"\"\n",
    "    lat1, lon1 = latlon1\n",
    "    lat2, lon2 = latlon2\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # r = 6370996.81  # 地球半径\n",
    "    # distance = c * r\n",
    "    distance = c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_center_dict = {}\n",
    "with open('dataset/train_data/city_A/grid_attr.csv', 'r') as f:\n",
    "    for line in f:        \n",
    "        items = line.strip().split(',')\n",
    "        ID = items[2]\n",
    "        if ID not in grid_center_dict:\n",
    "            grid_center_dict[ID] = []\n",
    "        grid_center_dict[ID].append(items[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146.76581927,  30.24247099])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in grid_center_dict:\n",
    "    grid_center_dict[k] = np.array(center_geolocation(grid_center_dict[k]))\n",
    "grid_center_dict['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_region_id(grid):\n",
    "    distance_dict = {}\n",
    "    for k in grid_center_dict:\n",
    "        distance_dict[k] = np.linalg.norm(grid - grid_center_dict[k])\n",
    "    return min(distance_dict, key=distance_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(result1.shape[0]):\n",
    "    if result1.loc[i, 'region_id'] == -1:\n",
    "        grid = result1.loc[i,['grid_x','grid_y']].values\n",
    "        result1.loc[i,'region_id'] = set_region_id(grid)\n",
    "result1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}